{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><div align=\"center\">MNIST Database</div></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img src=\"https://imgur.com/LHGvkC1.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction, what is MNIST?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The set of images in the MNIST database consist of digits written by high school students and employees of the United States Census Bureau. The MNIST database contains 60,000 training images and 10,000 testing images. Note this information was taken from wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Reading in the date and data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import gzip\n",
    "\n",
    "np.random.seed(1212)\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras import optimizers\n",
    "\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt #for plotting\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "sns.set_style('whitegrid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('/Users/rossheaney/Desktop/Workspace/FourthYear/ET/project/G00345608/MNIST_Datset_Files/t10k-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    file_content1 = f.read()\n",
    "    \n",
    "with gzip.open('/Users/rossheaney/Desktop/Workspace/FourthYear/ET/project/G00345608/MNIST_Datset_Files/train-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    file_content2 = f.read()\n",
    "\n",
    "    \n",
    "with gzip.open('/Users/rossheaney/Desktop/Workspace/FourthYear/ET/project/G00345608/MNIST_Datset_Files/t10k-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    label_content1 = f.read()\n",
    "    \n",
    "with gzip.open('/Users/rossheaney/Desktop/Workspace/FourthYear/ET/project/G00345608/MNIST_Datset_Files/train-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    label_content2 = f.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Magic number is outputted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2051"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int.from_bytes(file_content1[0:4], byteorder='big')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of images is outputted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int.from_bytes(file_content1[5:8], byteorder='big')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing the data so we know what to expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:  28 \n",
      "Columns:  28 \n",
      "Total:  784\n"
     ]
    }
   ],
   "source": [
    "row = int.from_bytes(file_content1[8:12], byteorder='big')\n",
    "col = int.from_bytes(file_content1[12:16], byteorder='big')\n",
    "tot = row*col\n",
    "\n",
    "print(\"Rows: \", row,\"\\nColumns: \", col,\"\\nTotal: \", tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output a plot of the image using matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a40c1b710>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = ~np.array(list(file_content1[16:800])).reshape(28,28).astype(np.uint8)\n",
    "\n",
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cv2.imwrite('test.png', image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what we have seen above is that the data is correct so now we can proceed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now discuss the code to save the images properly so we can train our model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing some exploration\n",
    "\n",
    "The biggest problem with the current dataset is that it's in a very unfriendly format.\n",
    "I will explore how to convert to CSV and I will explore the CSV files below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration of the CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I am using the MNIST in csv format to explore the data and build the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a look at what we are dealing with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: int64(785)\n",
      "memory usage: 251.5 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28000 entries, 0 to 27999\n",
      "Columns: 784 entries, pixel0 to pixel783\n",
      "dtypes: int64(784)\n",
      "memory usage: 167.5 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "\n",
       "[2 rows x 785 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "\n",
       "[2 rows x 784 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = pd.read_csv(\"/Users/rossheaney/Desktop/Workspace/FourthYear/ET/project/G00345608/MNIST_Datset_Files/train.csv\")\n",
    "test = pd.read_csv(\"/Users/rossheaney/Desktop/Workspace/FourthYear/ET/project/G00345608/MNIST_Datset_Files/test.csv\")\n",
    "\n",
    "display(train.info())\n",
    "\n",
    "display(test.info())\n",
    "\n",
    "display(train.head(n = 2))\n",
    "display(test.head(n = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This figure shows the distribution of the numbers across the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAHfCAYAAAAVw3+UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAexklEQVR4nO3df5Dkd13n8dduNptsT36QVEKyiSHLD/04p1dIlrug5JdeOAy/iys9PEEBlbszpcSDEsEE4omgiLk7FUqMxMRT6upMhBI1EhWEgEHu1pCQc/wE9sjlN7sJ+bE7HTNsdu6P7i0muzO7PbG/25+ZeTyqtuj+9mc27y+z0/vc7/fb3evm5+cDAEAb1k96AAAAvkmcAQA0RJwBADREnAEANEScAQA0RJwBADRkw6QHGJdt27Z5TxAAYMXYunXrusW2r5o4S5KtW7dOegQAgEPatm3bko85rQkA0BBxBgDQEHEGANAQcQYA0BBxBgDQEHEGANAQcQYA0BBxBgDQEHEGANAQcQYA0BBxBgDQEHEGANAQcQYA0BBxBgDQEHEGANAQcQYA0BBxBgDQEHEGANAQcQYA0JANkx6Af5q5R+7PN3bvnPQYIzvymJOz8fhTJz0GADRLnK1w39i9M3d97NJJjzGyM171bnEGAAfhtCYAQEPEGQBAQ8QZAEBDxBkAQEPEGQBAQ8QZAEBDxBkAQEPEGQBAQ8QZAEBDxBkAQEPEGQBAQ8QZAEBDxBkAQEPEGQBAQ8QZAEBDxBkAQEPEGQBAQ8QZAEBDxBkAQEPEGQBAQ8QZAEBDxBkAQEPEGQBAQzZMegAAONwe2b0nux/bO+kxRnbMpvU5/hh/Za8VvtMArDm7H9ubj332oUmPMbJXnXNCjj9m0lNwuDitCQDQEHEGANAQpzVhQr6++7480t8x6TGW5fje03PiMZsnPQbAqibOYEIe6e/INX/9s5MeY1l+9IL3iTOAjjmtCQDQEHEGANAQcQYA0BBxBgDQEHEGANAQcQYA0BBxBgDQEHEGANAQcQYA0BBxBgDQEHEGANAQcQYA0BAffA4ArBh7Hn48e3fNTXqMZVl/7MZseNpRI68XZzRt96P3pT+7Y9JjjKw39fQcc9zmSY8BsGrt3TWXh667fdJjLMsJ/+bbEnHGatGf3ZHP/PnbJj3GyM77/l8RZwD8k7jmDACgIeIMAKAhq/605p5HdmXv7tlJj7Es64+Zyobjj530GMAadv/ux/LAY49PeoyRnbTpqJx6zKZJjwFjserjbO/u2Tzyx3856TGW5fhXXJiIM2CCHnjs8Vz2mdsmPcbIfvG87xRnrBpOawIANEScAQA0RJwBADREnAEANGTVvyAAmIz7dj+UnY89MukxluXkTcdn8zEnTHoMYI0TZ0Andj72SH7us78/6TGW5ZfPea04Y8V7/NE9mdu9d9JjLMvGY9bnqOMkyT7+nwCAVWRu99585c8envQYy/KclzwtRx036Sna0WmclVKenmRbkhcl2ZPk6iTzSW5LcnGtdW8p5V1JXjp8/JJa6xdKKc9ZbG2XswIAtKCzFwSUUo5M8qEkjw03XZHk0lrruUnWJXllKeWsJOcnOTvJa5J8YKm1Xc0JANCSLl+t+f4kv5Xk3uH9rUk+Pbx9fZILk5yT5IZa63yt9c4kG0opJy+xFgBg1evktGYp5fVJdtZaP1FKeftw87pa6/zw9q4kxyc5LsmDC7503/bF1h7SzMzMAds2bzhq2fNPWr/fz/ZF9mUxJx3R73ia8erP9nPniPuWJJs2rrD96/cX/XO4mL2bVta+Jcvbv35v/tCLGrOc/VvtZjeN9LTbjNnZfmYeuG/k9Uf0Nnc4zfjN9vuZmdk+0toTj1xZ+5YMfvbuHnH/Nq9feS/a6fdns33m7pHXd3XN2RuTzJdSLkzyXUl+L8nTFzx+bJKHkzw6vL3/9r2LbDuk6enpA7bN3XN/VtaL+ZNer5fp05810trZe770pLptXW+ql+nTD/w+LWXHfbd0OM349Xq9bHn2aPv31R0ra9+Swf49c8to+3frzju6HaYDvV4v02dumfQYTbht58q6oHxqqpfpLaeNvP6enXNJVs4Hu0/1ejn9zNF+9nbdO5dkrtuBxqzX6+WU00bbv7m7dq2g79xArzeV6TNOfdK2bdu2Lbm+k9Oatdbzaq3n11ovSPLFJD+S5PpSygXDJRcluTHJ55K8uJSyvpTyjCTra60PJLl5kbUAAKve4XwrjbckubKUsjHJTJJra61PlFJuTHJTBqF48VJrD+OcAAAT03mcDY+e7XP+Io9fnuTy/bbdvthaAIDVzmdrAgA0RJwBADREnAEANEScAQA0RJwBADREnAEANEScAQA0RJwBADREnAEANEScAQA0RJwBADREnAEANEScAQA0ZMOkBwBYie7bvSs7+/1Jj7EsJ/d62XzMsZMeAzgEcQbwFOzs9/OOz/zlpMdYlvecd6E4gxXAaU0AgIaIMwCAhogzAICGiDMAgIaIMwCAhogzAICGiDMAgIaIMwCAhogzAICGiDMAgIaIMwCAhogzAICGiDMAgIaIMwCAhogzAICGiDMAgIaIMwCAhogzAICGiDMAgIaIMwCAhogzAICGiDMAgIaIMwCAhogzAICGiDMAgIaIMwCAhogzAICGiDMAgIaIMwCAhogzAICGiDMAgIaIMwCAhogzAICGiDMAgIaIMwCAhogzAICGiDMAgIaIMwCAhogzAICGiDMAgIaIMwCAhogzAICGiDMAgIaIMwCAhogzAICGiDMAgIaIMwCAhogzAICGiDMAgIaIMwCAhogzAICGiDMAgIaIMwCAhogzAICGiDMAgIaIMwCAhogzAICGiDMAgIaIMwCAhogzAICGiDMAgIaIMwCAhogzAICGiDMAgIaIMwCAhmzo6jcupRyR5MokJckTSd6QZF2Sq5PMJ7ktycW11r2llHcleWmSPUkuqbV+oZTynMXWdjUvAEALujxy9vIkqbW+MMk7k1wx/HVprfXcDELtlaWUs5Kcn+TsJK9J8oHh1x+wtsNZAQCa0Fmc1Vo/luRNw7tnJvlakq1JPj3cdn2SC5Ock+SGWut8rfXOJBtKKScvsRYAYFXr9JqzWuueUso1SX4jybVJ1tVa54cP70pyfJLjkjyy4Mv2bV9sLQDAqtbZNWf71Fp/tJTytiR/m2TTgoeOTfJwkkeHt/ffvneRbQc1MzNzwLbNG45a/tAT1u/3s32RfVnMSUf0O55mvPqz/dw54r4lyaaNK2z/+v1F/xwuZu+mlbVvyfL2r9+bP/Sixixr/zatxOeW2ZH3b3bTyvr38OxsPzMP3Dfy+iN6mzucZvxm+/3MzGwfae2JR66sfUsGP3t3j7h/m9ef0PE049fvz2b7zN0jr+/yBQGvS/Ittdb3JulnEFv/u5RyQa31r5NclORTSb6S5H2llPcn+ZYk62utD5RSbl5k7UFNT08fsG3unvufdFhuJej1epk+/VkjrZ2950t5sON5xqk31cv06Qd+n5ay475bOpxm/Hq9XrY8e7T9++qOlbVvyWD/nrlltP27decd3Q7TgV6vl+kzt4y09tYdX+t2mA70elOZ3jLac8ttOw/57+GmTE31Mr3ltJHX37NzLsnj3Q00ZlO9Xk4/c7SfvV33ziWZ63agMev1ejnltNH2b+6uXSvoOzfQ601l+oxTn7Rt27ZtS67v8sjZHyX53VLKZ5IcmeSSJDNJriylbBzevrbW+kQp5cYkN2VwmvXi4de/Zf+1Hc4KANCEzuKs1jqb5AcXeej8RdZenuTy/bbdvthaAIDVzJvQAgA0RJwBADREnAEANEScAQA0RJwBADREnAEANEScAQA0RJwBADREnAEANEScAQA0RJwBADREnAEANEScAQA0RJwBADTkkHFWSrl8kW1XdDINAMAat2GpB0op70zytCQ/XEo5bsFDRyZ5WZL/1PFsAABrzsGOnN2cZDbJ3uH/7vv1QJLXdT8aAMDas+SRs1rrx5N8vJTyZ7XWmw7jTAAAa9aScbbAA6WUK5OcmGTdvo211ld3NhUAwBo1Spz9XganOK9PMt/tOAAAa9socXZMrfUnO58EAICR3udseynllM4nAQBgpCNne5P8n1LK/0ry2L6NrjkDABi/UeLsT4e/AADo2CHjrNb64cMxCAAAI8RZKeWhLPIqzVrriZ1MBACwho1yWvP5C25vTPLvkjzazTgAAGvbKKc1t++36bJSyt8m+dVuRgIAWLtGeSuNJymlfGsSb60BANCB5V5ztj7JpiRv73IoAIC1arnXnM0neajW+lBH8wAArGmHPK05vObsuUl+Lsk7k1zU9VAAAGvVIeOslPIzSS5PUpP8fZK3l1Kc1gQA6MAopzVfn+TcWusjSVJK+e0kf5PkvR3OBQCwJo30as19YTa8/XCSb3Q2EQDAGjbKkbM7SykXJ/mt4f3/mOTu7kYCAFi7Rjly9pNJfijJY0n6SX44ycVdDgUAsFaN8gkBdyU5p5RybJL1C09xAgAwXgc9clZKuayU8n1JUmvdleS/llJ+/rBMBgCwBi0ZZ6WUtyZ5WZK7Fmz+UJJXllLe3PVgAABr0cGOnL0uyUW11i/v21Br/XySVyT5sa4HAwBYiw4WZ0/UWr++/8Za6/1JnuhuJACAtetgcbaulLJx/43DbQdsBwDgn+5gcfanSd6zyPb3JPlkN+MAAKxtB3srjXcn+Xgp5StJPp9ByP3LJF9N8qrDMBsAwJqzZJzVWv8xyYuGb6Xx/CR7k3yw1vrZwzUcAMBaM8qb0H4yTmMCABwWI33wOQAAh4c4AwBoiDgDAGjIkteclVI+mmR+qcdrra/uZCIAgDXsYC8I+JPDNgUAAEkO/lYaH17qsVLKM7sZBwBgbTvkW2mUUn48yfuSTCVZl8F1ag8lObnb0QAA1p5RXhDw80lenuQvkpyd5BeT/M8uhwIAWKtGibOv11o/l+TmJCfVWn8hyfd2OxYAwNo0Spx9o5TytCRfzuBjnJLkiO5GAgBYuw55zVmSDyf50ySvSHJzKeWVGYQaAABjdsgjZ7XWK5N8f631wSTnJvnVJD/U9WAAAGvRIeOslPJ3tdZdSVJr/X+11uuS/E3nkwEArEEH+4SAv0iyNclxpZSv7/c1X+x6MACAtehg15z9QJKTklyV5A0Ltu9Jck+XQwEArFUH+4SAh5M8nOS8Usq3JDk/yZFJPlVr3XOY5gMAWFNGuebsRRm8x9kPJfnBJLeUUl7W9WAAAGvRKG+l8e4k31trvS1JSin/PMk18cHoAABjN8qb0G7cF2ZJUmv9UrwJLQBAJ0aJs8dLKc/bd6eUclaSx7sbCQBg7RrltObbklxfSplJMp/kO5P8206nAgBYo5Y8clZKOSpJaq2fziDIrkjy60m+s9b6qcMzHgDA2nKwI2c3JTkrSWqtDyT5+GGZCABgDTvYNWfrDtsUAAAkOfiRs6OHLwRYNNJqrX/XzUgAAGvXweLsWUmuy+JxNj98HACAMTpYnP19rfV5B3kcAIAxG+V9zgAAOEwOFmefOWxTAACQ5CBxVmt98+EcBAAApzUBAJoizgAAGiLOAAAaIs4AABpysPc5e8pKKUcmuSrJliRHJXl3kr9PcnUGb2B7W5KLa617SynvSvLSJHuSXFJr/UIp5TmLre1iVgCAlnR15Oy1SR6stZ6b5KIkv5nkiiSXDretS/LKUspZSc5PcnaS1yT5wPDrD1jb0ZwAAE3pKs7+MMllC+7vSbI1yaeH969PcmGSc5LcUGudr7XemWRDKeXkJdYCAKx6nZzWrLXuTpJSyrFJrk1yaZL311rnh0t2JTk+yXFJHlzwpfu2r1tk7SHNzMwcsG3zhqOewh5MVr/fz/ZF9mUxJx3R73ia8erP9nPniPuWJJs2rrD96/cX/XO4mL2bVta+Jcvbv35v/tCLGrOs/du0Ep9bZkfev9lNIz3tNmN2tp+ZB+4bef0Rvc0dTjN+s/1+Zma2j7T2xCNX1r4lg5+9u0fcv83rT+h4mvHr92ezfebukdd3EmdJUko5I8lHk3yw1vqRUsr7Fjx8bJKHkzw6vL3/9r2LbDuk6enpA7bN3XN/Hlne6BPX6/Uyffponys/e8+XnlS3retN9TJ9+oHfp6XsuO+WDqcZv16vly3PHm3/vrpjZe1bMti/Z24Zbf9u3XlHt8N0oNfrZfrMLSOtvXXH17odpgO93lSmt4z23HLbzpGedpsxNdXL9JbTRl5/z865JI93N9CYTfV6Of3M0X72dt07l2Su24HGrNfr5ZTTRtu/ubt2raDv3ECvN5XpM0590rZt27Ytub6T05qllFOS3JDkbbXWq4abby6lXDC8fVGSG5N8LsmLSynrSynPSLK+1vrAEmsBAFa9ro6cvSPJCUkuK6Xsu/bszUl+vZSyMclMkmtrrU+UUm5MclMGoXjxcO1bkly5cG1HcwIANKWra87enEGM7e/8RdZenuTy/bbdvthaAIDVzpvQAgA0RJwBADREnAEANEScAQA0RJwBADREnAEANEScAQA0RJwBADREnAEANEScAQA0RJwBADREnAEANEScAQA0RJwBADREnAEANEScAQA0RJwBADREnAEANEScAQA0RJwBADREnAEANEScAQA0RJwBADREnAEANEScAQA0RJwBADREnAEANEScAQA0RJwBADREnAEANEScAQA0RJwBADREnAEANEScAQA0RJwBADREnAEANEScAQA0RJwBADREnAEANEScAQA0RJwBADREnAEANEScAQA0RJwBADREnAEANEScAQA0RJwBADREnAEANEScAQA0RJwBADREnAEANEScAQA0RJwBADREnAEANEScAQA0RJwBADREnAEANEScAQA0RJwBADREnAEANEScAQA0RJwBADREnAEANEScAQA0RJwBADREnAEANEScAQA0RJwBADREnAEANEScAQA0RJwBADREnAEANEScAQA0RJwBADREnAEANEScAQA0RJwBADREnAEANEScAQA0RJwBADRkQ5e/eSnl7CS/Umu9oJTynCRXJ5lPcluSi2ute0sp70ry0iR7klxSa/3CUmu7nBUAoAWdHTkrpfxskt9JcvRw0xVJLq21nptkXZJXllLOSnJ+krOTvCbJB5Za29WcAAAt6fK05vYkr15wf2uSTw9vX5/kwiTnJLmh1jpfa70zyYZSyslLrAUAWPU6O61Za72ulLJlwaZ1tdb54e1dSY5PclySBxes2bd9sbWHNDMzc8C2zRuOWt7gDej3+9m+yL4s5qQj+h1PM1792X7uHHHfkmTTxhW2f/3+on8OF7N308rat2R5+9fvzR96UWOWtX+bVuJzy+zI+ze7aaSn3WbMzvYz88B9I68/ore5w2nGb7bfz8zM9pHWnnjkytq3ZPCzd/eI+7d5/QkdTzN+/f5sts/cPfL6Tq8528/Ca8aOTfJwkkeHt/ffvtjaQ5qenj5g29w99+eR5U46Yb1eL9OnP2uktbP3fOlJddu63lQv06cf+H1ayo77bulwmvHr9XrZ8uzR9u+rO1bWviWD/XvmltH279add3Q7TAd6vV6mz9wy0tpbd3yt22E60OtNZXrLaM8tt+0c6Wm3GVNTvUxvOW3k9ffsnEvyeHcDjdlUr5fTzxztZ2/XvXNJ5rodaMx6vV5OOW20/Zu7a9cK+s4N9HpTmT7j1Cdt27Zt25LrD+erNW8upVwwvH1RkhuTfC7Ji0sp60spz0iyvtb6wBJrAQBWvcN55OwtSa4spWxMMpPk2lrrE6WUG5PclEEoXrzU2sM4JwDAxHQaZ7XWO5K8YHj79gxembn/msuTXL7ftkXXAgCsdt6EFgCgIeIMAKAh4gwAoCHiDACgIeIMAKAh4gwAoCHiDACgIeIMAKAh4gwAoCHiDACgIeIMAKAh4gwAoCHiDACgIeIMAKAh4gwAoCHiDACgIeIMAKAh4gwAoCHiDACgIeIMAKAh4gwAoCHiDACgIeIMAKAh4gwAoCHiDACgIeIMAKAh4gwAoCHiDACgIeIMAKAh4gwAoCHiDACgIeIMAKAh4gwAoCHiDACgIeIMAKAh4gwAoCHiDACgIeIMAKAh4gwAoCHiDACgIeIMAKAh4gwAoCHiDACgIeIMAKAh4gwAoCHiDACgIeIMAKAh4gwAoCHiDACgIeIMAKAh4gwAoCHiDACgIeIMAKAh4gwAoCHiDACgIeIMAKAh4gwAoCHiDACgIeIMAKAh4gwAoCHiDACgIeIMAKAh4gwAoCHiDACgIeIMAKAh4gwAoCHiDACgIeIMAKAh4gwAoCHiDACgIeIMAKAh4gwAoCHiDACgIeIMAKAh4gwAoCHiDACgIeIMAKAh4gwAoCHiDACgIeIMAKAh4gwAoCEbJj3AUkop65N8MMlzkzye5MdrrV+Z7FQAAN1q+cjZq5IcXWv97iQ/l+TXJjwPAEDnWo6zc5L8eZLUWj+f5PmTHQcAoHvr5ufnJz3Dokopv5Pkulrr9cP7dyZ5Vq11z2Lrt23b1uaOAAAsYuvWresW297sNWdJHk1y7IL765cKs2TpHQQAWElaPq35uSQvSZJSyguSfGmy4wAAdK/lI2cfTfKiUsrfJFmX5A0TngcAoHPNXnMGALAWtXxaEwBgzRFnAAANafmasyathU8uKKWcneRXaq0XTHqWcSqlHJnkqiRbkhyV5N211j+e6FBjVEo5IsmVSUqSJ5K8oda6fbJTjV8p5elJtiV5Ua31HyY9zziVUm5O8sjw7ldrravqWttSytuTvCLJxiQfrLV+eMIjjU0p5fVJXj+8e3SS70pyaq314UnNNC7D585rMnjufCLJT6ymn71SylFJfjfJszJ4p4iLa61fnuRMjpwt36r+5IJSys8m+Z0MnlxWm9cmebDWem6Si5L85oTnGbeXJ0mt9YVJ3pnkismOM37DvyQ+lOSxSc8ybqWUo5Ok1nrB8NdqC7MLknxPkhcmOT/JGRMdaMxqrVfv+95l8I+Hn14NYTb0kiQbaq3fk+Q/J/mlCc8zbj+RZHet9QVJfioN/N0gzpZvtX9ywfYkr570EB35wySXLbi/5PvmrUS11o8ledPw7plJvjbBcbry/iS/leTeSQ/Sgecm6ZVSbiilfHL4FkKryYszeEukjyb5eJI/mew43SilPD/Jd9Raf3vSs4zR7Uk2DM8cHZfkGxOeZ9z+WZLrk6TWWpNMT3YccfZUHJdvnnZIkidKKavm9HCt9bqsvh+8JEmtdXetdVcp5dgk1ya5dNIzjVutdU8p5Zokv5HBPq4aw9NGO2utn5j0LB3pZxCfL07yH5L8wWp6bklyUgb/mP2BfHP/VuObh78jyS9Meogx253BKc1/yODSiV+f6DTj98UkLyulrBv+o+j04WUiEyPOlm9Zn1xAW0opZyT5VJL/Xmv9yKTn6UKt9UeTfFuSK0spU5OeZ4zemMF7H/51Btfz/F4p5dTJjjRWtyf5/VrrfK319iQPJtk84ZnG6cEkn6i1zg2PTvxjkpMnPNNYlVKeluTba62fmvQsY/YzGXzvvi2DI7zX7DsNv0pclcHf7Z/K4PKQbbXWJyY5kDhbPp9csEKVUk5JckOSt9Var5r0PONWSnnd8ILrZHAUZm8GF++uCrXW82qt5w+v6flikh+ptd4/4bHG6Y0ZXsNaSjktg6P09010ovH6bJLvHx6dOC3JVAbBtpqcl+QvJz1EBx7KN88YfT3JkUkmemRpzP5Fks8On1s+muT/TnYcr9Z8Knxywcr1jiQnJLmslLLv2rOLaq2r5eLyP0ryu6WUz2Tw5HlJrfUfJzwTo/twkqtLKZ9NMp/kjavpqHyt9U9KKecl+UIGBwYunvTRiQ6UNPAXewf+S5KrSik3ZvBK23fUWmcnPNM4fTnJL5ZS3prk4SQ/NuF5fEIAAEBLnNYEAGiIOAMAaIg4AwBoiDgDAGiIOAMAaIg4A1aVUsqWUsp8KeXH9tv+1lLK1WP6b9wx/JgegLETZ8BqtDfJr5VSyqQHAVgub0ILrEaPZfBu+x8ppXx3rXVu3wPDo2e31Vrfv//9UsodST6S5PsyeMPi9yV5YZKtGXzm7Ctqrfs+dP3iUspzkxyV5Nf2fepEKeXlGXxu68YMPqnhrbXWm0oplyf57iSnJbml1vrazvYeWNEcOQNWq1/K4AOb37PMrzu61vqCJO9M8ttJ/lut9blJ7kry+gXrHqu1npXkRUneW0r5jlLKtw7/ey+ptT4vyZuS/NGCzzg9M8nzhBlwMI6cAatSrXVvKeW1Sb5YSvnEMr70uuH/bk9yf631lgX3T1yw7kPD/869pZQbkvyrJHsy+LDyv1pwRnVvkucMb39+NX0kE9ANR86AVavWeleSf5/kmiQnDTfPZ/C5uPts3O/LHl9w+xsH+e0Xfi7k+uHaI5L8Va31u/b9SvKCJLcN1+1e3h4Aa5E4A1a1Wuu1Sa5Pcslw084kz0+SUsppSc5/ir/164e/xzOSXJjkr4a//nUp5duHj70kya1JNj3F/wawBjmtCawFP53knOHt30jyB6WUmuSOJJ98ir/n0aWUv8vgyNtP1VpvT5JSypuS/I9SyroMTnO+ota62wtHgVGtm5+fn/QMAAAMOa0JANAQcQYA0BBxBgDQEHEGANAQcQYA0BBxBgDQEHEGANAQcQYA0JD/DwCnCI8v1fjlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = \"label\", data = train)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(10, 8)\n",
    "plt.xlabel(\"Number\")\n",
    "plt.ylabel(\"Total Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purely integer-location based indexing for selection by position.\n",
    "\n",
    ".iloc[] is primarily integer position based (from 0 to length-1 of the axis), but may also be used with a boolean array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's what I'm doing here. Further reading on iloc and pandas in general can be found at ===> https://pandas.pydata.org/pandas-docs/stable/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 784)\n"
     ]
    }
   ],
   "source": [
    "df_features = train.iloc[:, 1:785]\n",
    "df_label = train.iloc[:, 0]\n",
    "\n",
    "X_test = test.iloc[:, 0:784]\n",
    "\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets spilt our training data up. We need to split it up randomly as we need to train our model and also test it on unseen data. If we train and test our model on the same data then the accuracy result is obviously going to be heavily skewed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_cv, y_train, y_cv = train_test_split(df_features, df_label, \n",
    "                                                test_size = 0.2,\n",
    "                                                random_state = 1212)\n",
    "\n",
    "X_train = X_train.as_matrix().reshape(33600, 784) #(33600, 784)\n",
    "X_cv = X_cv.as_matrix().reshape(8400, 784) #(8400, 784)\n",
    "\n",
    "X_test = X_test.as_matrix().reshape(28000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 255)\n"
     ]
    }
   ],
   "source": [
    "print((min(X_train[1]), max(X_train[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of standardization (or Z-score normalization) is that the features will be rescaled so that they’ll have the properties of a standard normal distribution with $$μ=0  and  σ=1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where μ is the mean (average) and σ is the standard deviation from the mean; standard scores (also called z scores) of the samples are calculated as follows:\n",
    "\n",
    "$$z=x−μσ$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardizing the features so that they are centered around 0 with a standard deviation of 1 is not only important if we are comparing measurements that have different units but it's also very necessary for many of these alogorithms to work. I have adopted the above from =====> https://sebastianraschka.com/Articles/2014_about_feature_scaling.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Normalization \n",
    "X_train = X_train.astype('float32'); X_cv= X_cv.astype('float32'); X_test = X_test.astype('float32')\n",
    "X_train /= 255; X_cv /= 255; X_test /= 255\n",
    "\n",
    "# Convert labels to One Hot Encoded\n",
    "num_digits = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_digits)\n",
    "y_cv = keras.utils.to_categorical(y_cv, num_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Printing 2 examples of labels after conversion\n",
    "print(y_train[0]) # 2\n",
    "print(y_train[3]) # 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explaination of what is below\n",
    "\n",
    "Below is several neural networks. We will examine the models and the most accurate will be chosen as our model to test our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model contains a neural networks with an activation function set to ReLu. ReLu stands forrectified linear unit and can be mathematically defined as $$ y = max(0, x) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Parameters\n",
    "n_input = 784 # number of features\n",
    "n_hidden_1 = 300\n",
    "n_hidden_2 = 100\n",
    "n_hidden_3 = 100\n",
    "n_hidden_4 = 200\n",
    "num_digits = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we're basically defining our input so that our neural network knows what to expect and how to handle the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Inp = Input(shape=(784,))\n",
    "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
    "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
    "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
    "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
    "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_1 (Dense)       (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_2 (Dense)       (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_3 (Dense)       (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_4 (Dense)       (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "Output_Layer (Dense)         (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 297,910\n",
      "Trainable params: 297,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Our model would have '6' layers - input layer, 4 hidden layer and 1 output layer\n",
    "model = Model(Inp, output)\n",
    "model.summary() # We have 297,910 parameters to estimate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Hyperparameters\n",
    "learning_rate = 0.1\n",
    "training_epochs = 20\n",
    "batch_size = 100\n",
    "sgd = optimizers.SGD(lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on optimizers and why we use them etc... ===> https://keras.io/optimizers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We rely on the plain vanilla Stochastic Gradient Descent as our optimizing methodology\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/20\n",
      " - 5s - loss: 1.8541 - acc: 0.4984 - val_loss: 1.0046 - val_acc: 0.7601\n",
      "Epoch 2/20\n",
      " - 4s - loss: 0.6481 - acc: 0.8293 - val_loss: 0.4640 - val_acc: 0.8719\n",
      "Epoch 3/20\n",
      " - 5s - loss: 0.4102 - acc: 0.8831 - val_loss: 0.3622 - val_acc: 0.8975\n",
      "Epoch 4/20\n",
      " - 7s - loss: 0.3378 - acc: 0.9028 - val_loss: 0.3122 - val_acc: 0.9102\n",
      "Epoch 5/20\n",
      " - 4s - loss: 0.2981 - acc: 0.9137 - val_loss: 0.2892 - val_acc: 0.9179\n",
      "Epoch 6/20\n",
      " - 3s - loss: 0.2685 - acc: 0.9226 - val_loss: 0.2652 - val_acc: 0.9240\n",
      "Epoch 7/20\n",
      " - 3s - loss: 0.2454 - acc: 0.9297 - val_loss: 0.2556 - val_acc: 0.9257\n",
      "Epoch 8/20\n",
      " - 3s - loss: 0.2274 - acc: 0.9352 - val_loss: 0.2322 - val_acc: 0.9335\n",
      "Epoch 9/20\n",
      " - 3s - loss: 0.2103 - acc: 0.9377 - val_loss: 0.2176 - val_acc: 0.9362\n",
      "Epoch 10/20\n",
      " - 3s - loss: 0.1953 - acc: 0.9440 - val_loss: 0.2053 - val_acc: 0.9394\n",
      "Epoch 11/20\n",
      " - 3s - loss: 0.1829 - acc: 0.9469 - val_loss: 0.1954 - val_acc: 0.9423\n",
      "Epoch 12/20\n",
      " - 3s - loss: 0.1708 - acc: 0.9504 - val_loss: 0.1850 - val_acc: 0.9452\n",
      "Epoch 13/20\n",
      " - 3s - loss: 0.1613 - acc: 0.9530 - val_loss: 0.1805 - val_acc: 0.9457\n",
      "Epoch 14/20\n",
      " - 3s - loss: 0.1516 - acc: 0.9559 - val_loss: 0.1764 - val_acc: 0.9469\n",
      "Epoch 15/20\n",
      " - 3s - loss: 0.1432 - acc: 0.9587 - val_loss: 0.1656 - val_acc: 0.9502\n",
      "Epoch 16/20\n",
      " - 3s - loss: 0.1354 - acc: 0.9604 - val_loss: 0.1595 - val_acc: 0.9529\n",
      "Epoch 17/20\n",
      " - 3s - loss: 0.1290 - acc: 0.9622 - val_loss: 0.1545 - val_acc: 0.9527\n",
      "Epoch 18/20\n",
      " - 3s - loss: 0.1218 - acc: 0.9646 - val_loss: 0.1478 - val_acc: 0.9562\n",
      "Epoch 19/20\n",
      " - 3s - loss: 0.1158 - acc: 0.9670 - val_loss: 0.1471 - val_acc: 0.9561\n",
      "Epoch 20/20\n",
      " - 3s - loss: 0.1101 - acc: 0.9682 - val_loss: 0.1409 - val_acc: 0.9583\n"
     ]
    }
   ],
   "source": [
    "history1 = model.fit(X_train, y_train,\n",
    "                     batch_size = batch_size,\n",
    "                     epochs = training_epochs,\n",
    "                     verbose = 2,\n",
    "                     validation_data=(X_cv, y_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets change the optimizer and see if we can get a better score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inp = Input(shape=(784,))\n",
    "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
    "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
    "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
    "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
    "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)\n",
    "\n",
    "# We rely on ADAM as our optimizing methodology\n",
    "adam = keras.optimizers.Adam(lr=learning_rate)\n",
    "model2 = Model(Inp, output)\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/20\n",
      " - 7s - loss: 0.3422 - acc: 0.8973 - val_loss: 0.1610 - val_acc: 0.9476\n",
      "Epoch 2/20\n",
      " - 5s - loss: 0.1267 - acc: 0.9606 - val_loss: 0.1188 - val_acc: 0.9624\n",
      "Epoch 3/20\n",
      " - 5s - loss: 0.0832 - acc: 0.9738 - val_loss: 0.1004 - val_acc: 0.9696\n",
      "Epoch 4/20\n",
      " - 5s - loss: 0.0612 - acc: 0.9799 - val_loss: 0.0998 - val_acc: 0.9707\n",
      "Epoch 5/20\n",
      " - 5s - loss: 0.0437 - acc: 0.9855 - val_loss: 0.1017 - val_acc: 0.9712\n",
      "Epoch 6/20\n",
      " - 5s - loss: 0.0399 - acc: 0.9865 - val_loss: 0.0991 - val_acc: 0.9731\n",
      "Epoch 7/20\n",
      " - 5s - loss: 0.0288 - acc: 0.9908 - val_loss: 0.1202 - val_acc: 0.9694\n",
      "Epoch 8/20\n",
      " - 5s - loss: 0.0263 - acc: 0.9917 - val_loss: 0.0921 - val_acc: 0.9763\n",
      "Epoch 9/20\n",
      " - 5s - loss: 0.0234 - acc: 0.9923 - val_loss: 0.1102 - val_acc: 0.9740\n",
      "Epoch 10/20\n",
      " - 5s - loss: 0.0250 - acc: 0.9915 - val_loss: 0.1014 - val_acc: 0.9755\n",
      "Epoch 11/20\n",
      " - 5s - loss: 0.0204 - acc: 0.9931 - val_loss: 0.1092 - val_acc: 0.9756\n",
      "Epoch 12/20\n",
      " - 5s - loss: 0.0161 - acc: 0.9947 - val_loss: 0.1172 - val_acc: 0.9777\n",
      "Epoch 13/20\n",
      " - 5s - loss: 0.0185 - acc: 0.9939 - val_loss: 0.1076 - val_acc: 0.9758\n",
      "Epoch 14/20\n",
      " - 5s - loss: 0.0185 - acc: 0.9940 - val_loss: 0.1139 - val_acc: 0.9761\n",
      "Epoch 15/20\n",
      " - 5s - loss: 0.0136 - acc: 0.9955 - val_loss: 0.1285 - val_acc: 0.9736\n",
      "Epoch 16/20\n",
      " - 5s - loss: 0.0125 - acc: 0.9955 - val_loss: 0.1078 - val_acc: 0.9768\n",
      "Epoch 17/20\n",
      " - 5s - loss: 0.0123 - acc: 0.9962 - val_loss: 0.1213 - val_acc: 0.9751\n",
      "Epoch 18/20\n",
      " - 5s - loss: 0.0119 - acc: 0.9963 - val_loss: 0.1012 - val_acc: 0.9782\n",
      "Epoch 19/20\n",
      " - 5s - loss: 0.0148 - acc: 0.9953 - val_loss: 0.1096 - val_acc: 0.9768\n",
      "Epoch 20/20\n",
      " - 5s - loss: 0.0123 - acc: 0.9957 - val_loss: 0.1227 - val_acc: 0.9758\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(X_train, y_train,\n",
    "                      batch_size = batch_size,\n",
    "                      epochs = training_epochs,\n",
    "                      verbose = 2,\n",
    "                      validation_data=(X_cv, y_cv))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets try something different here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inp = Input(shape=(784,))\n",
    "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
    "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
    "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
    "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
    "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)\n",
    "\n",
    "learning_rate = 0.01\n",
    "adam = keras.optimizers.Adam(lr=learning_rate)\n",
    "model2a = Model(Inp, output)\n",
    "\n",
    "model2a.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/20\n",
      " - 7s - loss: 0.3402 - acc: 0.8964 - val_loss: 0.1936 - val_acc: 0.9431\n",
      "Epoch 2/20\n",
      " - 5s - loss: 0.1262 - acc: 0.9608 - val_loss: 0.1266 - val_acc: 0.9611\n",
      "Epoch 3/20\n",
      " - 5s - loss: 0.0830 - acc: 0.9743 - val_loss: 0.1115 - val_acc: 0.9668\n",
      "Epoch 4/20\n",
      " - 5s - loss: 0.0608 - acc: 0.9808 - val_loss: 0.0989 - val_acc: 0.9706\n",
      "Epoch 5/20\n",
      " - 5s - loss: 0.0458 - acc: 0.9859 - val_loss: 0.1103 - val_acc: 0.9699\n",
      "Epoch 6/20\n",
      " - 5s - loss: 0.0373 - acc: 0.9879 - val_loss: 0.0952 - val_acc: 0.9748\n",
      "Epoch 7/20\n",
      " - 5s - loss: 0.0334 - acc: 0.9890 - val_loss: 0.1022 - val_acc: 0.9715\n",
      "Epoch 8/20\n",
      " - 5s - loss: 0.0209 - acc: 0.9933 - val_loss: 0.1023 - val_acc: 0.9749\n",
      "Epoch 9/20\n",
      " - 5s - loss: 0.0224 - acc: 0.9928 - val_loss: 0.1201 - val_acc: 0.9702\n",
      "Epoch 10/20\n",
      " - 5s - loss: 0.0269 - acc: 0.9915 - val_loss: 0.1219 - val_acc: 0.9705\n",
      "Epoch 11/20\n",
      " - 5s - loss: 0.0167 - acc: 0.9938 - val_loss: 0.1269 - val_acc: 0.9744\n",
      "Epoch 12/20\n",
      " - 5s - loss: 0.0216 - acc: 0.9929 - val_loss: 0.1066 - val_acc: 0.9750\n",
      "Epoch 13/20\n",
      " - 5s - loss: 0.0150 - acc: 0.9954 - val_loss: 0.1083 - val_acc: 0.9769\n",
      "Epoch 14/20\n",
      " - 5s - loss: 0.0150 - acc: 0.9952 - val_loss: 0.1243 - val_acc: 0.9743\n",
      "Epoch 15/20\n",
      " - 5s - loss: 0.0100 - acc: 0.9970 - val_loss: 0.1212 - val_acc: 0.9745\n",
      "Epoch 16/20\n",
      " - 5s - loss: 0.0152 - acc: 0.9950 - val_loss: 0.1362 - val_acc: 0.9712\n",
      "Epoch 17/20\n",
      " - 5s - loss: 0.0169 - acc: 0.9950 - val_loss: 0.1162 - val_acc: 0.9748\n",
      "Epoch 18/20\n",
      " - 5s - loss: 0.0120 - acc: 0.9962 - val_loss: 0.1121 - val_acc: 0.9767\n",
      "Epoch 19/20\n",
      " - 5s - loss: 0.0130 - acc: 0.9960 - val_loss: 0.1203 - val_acc: 0.9777\n",
      "Epoch 20/20\n",
      " - 6s - loss: 0.0077 - acc: 0.9976 - val_loss: 0.1295 - val_acc: 0.9756\n"
     ]
    }
   ],
   "source": [
    "history2a = model2a.fit(X_train, y_train,\n",
    "                        batch_size = batch_size,\n",
    "                        epochs = training_epochs,\n",
    "                        verbose = 2,\n",
    "                        validation_data=(X_cv, y_cv))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets adjust the learning rate. The learning rate is a hyperparameter that controls how much to change the model in response to the estimated error each time the model weights are updated. Too much and the model will freak out and adjust way too much depending on the problem we are trying to solve. Too little and the model won't respond quick enough meaning we miss out on accuracy points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inp = Input(shape=(784,))\n",
    "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
    "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
    "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
    "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
    "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)\n",
    "\n",
    "learning_rate = 0.5\n",
    "adam = keras.optimizers.Adam(lr=learning_rate)\n",
    "model2b = Model(Inp, output)\n",
    "\n",
    "model2b.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/20\n",
      "33600/33600 [==============================] - 9s 255us/step - loss: 0.3379 - acc: 0.9015 - val_loss: 0.1499 - val_acc: 0.9557\n",
      "Epoch 2/20\n",
      "33600/33600 [==============================] - 8s 225us/step - loss: 0.1216 - acc: 0.9625 - val_loss: 0.1317 - val_acc: 0.9590\n",
      "Epoch 3/20\n",
      "33600/33600 [==============================] - 6s 165us/step - loss: 0.0797 - acc: 0.9753 - val_loss: 0.1151 - val_acc: 0.9639\n",
      "Epoch 4/20\n",
      "33600/33600 [==============================] - 6s 164us/step - loss: 0.0547 - acc: 0.9823 - val_loss: 0.0989 - val_acc: 0.9712\n",
      "Epoch 5/20\n",
      "33600/33600 [==============================] - 6s 172us/step - loss: 0.0458 - acc: 0.9854 - val_loss: 0.0907 - val_acc: 0.9749\n",
      "Epoch 6/20\n",
      "33600/33600 [==============================] - 5s 156us/step - loss: 0.0358 - acc: 0.9889 - val_loss: 0.0926 - val_acc: 0.9739\n",
      "Epoch 7/20\n",
      "33600/33600 [==============================] - 6s 164us/step - loss: 0.0289 - acc: 0.9910 - val_loss: 0.1191 - val_acc: 0.9683\n",
      "Epoch 8/20\n",
      "33600/33600 [==============================] - 7s 203us/step - loss: 0.0281 - acc: 0.9909 - val_loss: 0.1037 - val_acc: 0.9751\n",
      "Epoch 9/20\n",
      "33600/33600 [==============================] - 6s 184us/step - loss: 0.0257 - acc: 0.9919 - val_loss: 0.1155 - val_acc: 0.9696\n",
      "Epoch 10/20\n",
      "33600/33600 [==============================] - 9s 274us/step - loss: 0.0221 - acc: 0.9926 - val_loss: 0.0934 - val_acc: 0.9767\n",
      "Epoch 11/20\n",
      "33600/33600 [==============================] - 7s 218us/step - loss: 0.0197 - acc: 0.9939 - val_loss: 0.0981 - val_acc: 0.9775\n",
      "Epoch 12/20\n",
      "33600/33600 [==============================] - 7s 217us/step - loss: 0.0174 - acc: 0.9939 - val_loss: 0.1077 - val_acc: 0.9755\n",
      "Epoch 13/20\n",
      "33600/33600 [==============================] - 7s 212us/step - loss: 0.0183 - acc: 0.9942 - val_loss: 0.1190 - val_acc: 0.9736\n",
      "Epoch 14/20\n",
      "33600/33600 [==============================] - 6s 168us/step - loss: 0.0157 - acc: 0.9950 - val_loss: 0.1137 - val_acc: 0.9757\n",
      "Epoch 15/20\n",
      "33600/33600 [==============================] - 8s 237us/step - loss: 0.0119 - acc: 0.9964 - val_loss: 0.1240 - val_acc: 0.9746\n",
      "Epoch 16/20\n",
      "33600/33600 [==============================] - 9s 270us/step - loss: 0.0121 - acc: 0.9960 - val_loss: 0.1455 - val_acc: 0.9686\n",
      "Epoch 17/20\n",
      "33600/33600 [==============================] - 6s 164us/step - loss: 0.0172 - acc: 0.9946 - val_loss: 0.1066 - val_acc: 0.9742\n",
      "Epoch 18/20\n",
      "33600/33600 [==============================] - 7s 200us/step - loss: 0.0149 - acc: 0.9953 - val_loss: 0.1084 - val_acc: 0.9777\n",
      "Epoch 19/20\n",
      "33600/33600 [==============================] - 5s 160us/step - loss: 0.0105 - acc: 0.9965 - val_loss: 0.1108 - val_acc: 0.9779\n",
      "Epoch 20/20\n",
      "33600/33600 [==============================] - 6s 180us/step - loss: 0.0123 - acc: 0.9961 - val_loss: 0.1196 - val_acc: 0.9755\n"
     ]
    }
   ],
   "source": [
    "history2b = model2b.fit(X_train, y_train,\n",
    "                        batch_size = batch_size,\n",
    "                        epochs = training_epochs,\n",
    "                            validation_data=(X_cv, y_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets add another layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Parameters\n",
    "n_input = 784 # number of features\n",
    "n_hidden_1 = 300\n",
    "n_hidden_2 = 100\n",
    "n_hidden_3 = 100\n",
    "n_hidden_4 = 100\n",
    "n_hidden_5 = 200\n",
    "num_digits = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inp = Input(shape=(784,))\n",
    "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
    "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
    "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
    "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
    "x = Dense(n_hidden_5, activation='relu', name = \"Hidden_Layer_5\")(x)\n",
    "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_1 (Dense)       (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_2 (Dense)       (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_3 (Dense)       (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_4 (Dense)       (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_5 (Dense)       (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "Output_Layer (Dense)         (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 308,010\n",
      "Trainable params: 308,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Our model would have '7' layers - input layer, 5 hidden layer and 1 output layer\n",
    "model3 = Model(Inp, output)\n",
    "model3.summary() # We have 308,010 parameters to estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We rely on 'Adam' as our optimizing methodology\n",
    "adam = keras.optimizers.Adam(lr=0.01)\n",
    "\n",
    "model3.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/20\n",
      "33600/33600 [==============================] - 9s 261us/step - loss: 0.3613 - acc: 0.8931 - val_loss: 0.1938 - val_acc: 0.9436\n",
      "Epoch 2/20\n",
      "33600/33600 [==============================] - 6s 167us/step - loss: 0.1267 - acc: 0.9603 - val_loss: 0.1204 - val_acc: 0.9658\n",
      "Epoch 3/20\n",
      "33600/33600 [==============================] - 6s 169us/step - loss: 0.0859 - acc: 0.9739 - val_loss: 0.1284 - val_acc: 0.9589\n",
      "Epoch 4/20\n",
      "33600/33600 [==============================] - 6s 171us/step - loss: 0.0607 - acc: 0.9810 - val_loss: 0.1033 - val_acc: 0.9710\n",
      "Epoch 5/20\n",
      "33600/33600 [==============================] - 6s 166us/step - loss: 0.0463 - acc: 0.9857 - val_loss: 0.1239 - val_acc: 0.9670\n",
      "Epoch 6/20\n",
      "33600/33600 [==============================] - 5s 162us/step - loss: 0.0403 - acc: 0.9867 - val_loss: 0.0988 - val_acc: 0.9732\n",
      "Epoch 7/20\n",
      "33600/33600 [==============================] - 6s 175us/step - loss: 0.0391 - acc: 0.9873 - val_loss: 0.1121 - val_acc: 0.9688\n",
      "Epoch 8/20\n",
      "33600/33600 [==============================] - 6s 185us/step - loss: 0.0299 - acc: 0.9904 - val_loss: 0.0950 - val_acc: 0.9745\n",
      "Epoch 9/20\n",
      "33600/33600 [==============================] - 7s 221us/step - loss: 0.0224 - acc: 0.9924 - val_loss: 0.1115 - val_acc: 0.9730\n",
      "Epoch 10/20\n",
      "33600/33600 [==============================] - 7s 217us/step - loss: 0.0283 - acc: 0.9907 - val_loss: 0.1229 - val_acc: 0.9685\n",
      "Epoch 11/20\n",
      "33600/33600 [==============================] - 6s 185us/step - loss: 0.0205 - acc: 0.9936 - val_loss: 0.1022 - val_acc: 0.9757\n",
      "Epoch 12/20\n",
      "33600/33600 [==============================] - 13s 389us/step - loss: 0.0182 - acc: 0.9943 - val_loss: 0.1043 - val_acc: 0.9762\n",
      "Epoch 13/20\n",
      "33600/33600 [==============================] - 9s 254us/step - loss: 0.0231 - acc: 0.9923 - val_loss: 0.1079 - val_acc: 0.9736\n",
      "Epoch 14/20\n",
      "33600/33600 [==============================] - 9s 267us/step - loss: 0.0151 - acc: 0.9952 - val_loss: 0.1126 - val_acc: 0.9761\n",
      "Epoch 15/20\n",
      "33600/33600 [==============================] - 9s 256us/step - loss: 0.0170 - acc: 0.9950 - val_loss: 0.1106 - val_acc: 0.9751\n",
      "Epoch 16/20\n",
      "33600/33600 [==============================] - 8s 251us/step - loss: 0.0160 - acc: 0.9946 - val_loss: 0.1712 - val_acc: 0.9633\n",
      "Epoch 17/20\n",
      "33600/33600 [==============================] - 9s 281us/step - loss: 0.0157 - acc: 0.9952 - val_loss: 0.1161 - val_acc: 0.9751\n",
      "Epoch 18/20\n",
      "33600/33600 [==============================] - 10s 283us/step - loss: 0.0121 - acc: 0.9960 - val_loss: 0.1171 - val_acc: 0.9731\n",
      "Epoch 19/20\n",
      "33600/33600 [==============================] - 6s 187us/step - loss: 0.0155 - acc: 0.9955 - val_loss: 0.1345 - val_acc: 0.9706\n",
      "Epoch 20/20\n",
      "33600/33600 [==============================] - 6s 168us/step - loss: 0.0107 - acc: 0.9967 - val_loss: 0.1274 - val_acc: 0.9767\n"
     ]
    }
   ],
   "source": [
    "history3 = model3.fit(X_train, y_train,\n",
    "                      batch_size = batch_size,\n",
    "                      epochs = training_epochs,\n",
    "                      validation_data=(X_cv, y_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Parameters\n",
    "n_input = 784 # number of features\n",
    "n_hidden_1 = 300\n",
    "n_hidden_2 = 100\n",
    "n_hidden_3 = 100\n",
    "n_hidden_4 = 200\n",
    "num_digits = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "Inp = Input(shape=(784,))\n",
    "x = Dense(n_hidden_1, activation='relu', name = \"Hidden_Layer_1\")(Inp)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(n_hidden_2, activation='relu', name = \"Hidden_Layer_2\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(n_hidden_3, activation='relu', name = \"Hidden_Layer_3\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(n_hidden_4, activation='relu', name = \"Hidden_Layer_4\")(x)\n",
    "output = Dense(num_digits, activation='softmax', name = \"Output_Layer\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_1 (Dense)       (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_2 (Dense)       (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_3 (Dense)       (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "Hidden_Layer_4 (Dense)       (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "Output_Layer (Dense)         (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 297,910\n",
      "Trainable params: 297,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Our model would have '6' layers - input layer, 4 hidden layer and 1 output layer\n",
    "model4 = Model(Inp, output)\n",
    "model4.summary() # We have 297,910 parameters to estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/20\n",
      "33600/33600 [==============================] - 11s 318us/step - loss: 0.5838 - acc: 0.8126 - val_loss: 0.1887 - val_acc: 0.9444\n",
      "Epoch 2/20\n",
      "33600/33600 [==============================] - 7s 221us/step - loss: 0.2288 - acc: 0.9338 - val_loss: 0.1407 - val_acc: 0.9594\n",
      "Epoch 3/20\n",
      "33600/33600 [==============================] - 7s 221us/step - loss: 0.1721 - acc: 0.9507 - val_loss: 0.1206 - val_acc: 0.9642\n",
      "Epoch 4/20\n",
      "33600/33600 [==============================] - 8s 224us/step - loss: 0.1420 - acc: 0.9592 - val_loss: 0.1029 - val_acc: 0.9702\n",
      "Epoch 5/20\n",
      "33600/33600 [==============================] - 7s 222us/step - loss: 0.1201 - acc: 0.9657 - val_loss: 0.1042 - val_acc: 0.9701\n",
      "Epoch 6/20\n",
      "33600/33600 [==============================] - 7s 222us/step - loss: 0.1084 - acc: 0.9686 - val_loss: 0.0929 - val_acc: 0.9727\n",
      "Epoch 7/20\n",
      "33600/33600 [==============================] - 8s 228us/step - loss: 0.0966 - acc: 0.9720 - val_loss: 0.0940 - val_acc: 0.9744\n",
      "Epoch 8/20\n",
      "33600/33600 [==============================] - 8s 224us/step - loss: 0.0850 - acc: 0.9747 - val_loss: 0.1062 - val_acc: 0.9730\n",
      "Epoch 9/20\n",
      "33600/33600 [==============================] - 8s 226us/step - loss: 0.0835 - acc: 0.9751 - val_loss: 0.0903 - val_acc: 0.9746\n",
      "Epoch 10/20\n",
      "33600/33600 [==============================] - 8s 250us/step - loss: 0.0723 - acc: 0.9785 - val_loss: 0.0957 - val_acc: 0.9752\n",
      "Epoch 11/20\n",
      "33600/33600 [==============================] - 10s 287us/step - loss: 0.0691 - acc: 0.9793 - val_loss: 0.0890 - val_acc: 0.9755\n",
      "Epoch 12/20\n",
      "33600/33600 [==============================] - 7s 223us/step - loss: 0.0653 - acc: 0.9800 - val_loss: 0.0926 - val_acc: 0.9774\n",
      "Epoch 13/20\n",
      "33600/33600 [==============================] - 8s 226us/step - loss: 0.0621 - acc: 0.9819 - val_loss: 0.0924 - val_acc: 0.9781\n",
      "Epoch 14/20\n",
      "33600/33600 [==============================] - 8s 224us/step - loss: 0.0564 - acc: 0.9832 - val_loss: 0.0845 - val_acc: 0.9782\n",
      "Epoch 15/20\n",
      "33600/33600 [==============================] - 8s 250us/step - loss: 0.0607 - acc: 0.9817 - val_loss: 0.0889 - val_acc: 0.9786\n",
      "Epoch 16/20\n",
      "33600/33600 [==============================] - 8s 248us/step - loss: 0.0508 - acc: 0.9850 - val_loss: 0.0943 - val_acc: 0.9765\n",
      "Epoch 17/20\n",
      "33600/33600 [==============================] - 7s 220us/step - loss: 0.0498 - acc: 0.9845 - val_loss: 0.0891 - val_acc: 0.9792\n",
      "Epoch 18/20\n",
      "33600/33600 [==============================] - 8s 226us/step - loss: 0.0501 - acc: 0.9853 - val_loss: 0.0829 - val_acc: 0.9789\n",
      "Epoch 19/20\n",
      "33600/33600 [==============================] - 9s 256us/step - loss: 0.0486 - acc: 0.9852 - val_loss: 0.0890 - val_acc: 0.9774\n",
      "Epoch 20/20\n",
      "33600/33600 [==============================] - 10s 284us/step - loss: 0.0435 - acc: 0.9870 - val_loss: 0.0885 - val_acc: 0.9788\n"
     ]
    }
   ],
   "source": [
    "history = model4.fit(X_train, y_train,\n",
    "                    batch_size = batch_size,\n",
    "                    epochs = training_epochs,\n",
    "                    validation_data=(X_cv, y_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  Label\n",
       "0        1      2\n",
       "1        2      0\n",
       "2        3      9\n",
       "3        4      0\n",
       "4        5      3"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = pd.DataFrame(model4.predict(X_test, batch_size=200))\n",
    "test_pred = pd.DataFrame(test_pred.idxmax(axis = 1))\n",
    "test_pred.index.name = 'ImageId'\n",
    "test_pred = test_pred.rename(columns = {0: 'Label'}).reset_index()\n",
    "test_pred['ImageId'] = test_pred['ImageId'] + 1\n",
    "\n",
    "test_pred.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
